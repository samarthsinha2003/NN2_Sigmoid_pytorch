{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input size, hidden size, and output size\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training data\n",
    "X = torch.Tensor([[0, 0], [0, 1], [1, 0], [1, 1]]) #Tensor containing input data\n",
    "y = torch.Tensor([[0], [1], [1], [0]])             #Tensor containing the corresponding output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_size, hidden_size),  # Linear layer with input_size input neurons and hidden_size output neurons\n",
    "    torch.nn.Sigmoid(),                        # Sigmoid activation function\n",
    "    torch.nn.Linear(hidden_size, output_size), # Linear layer with hidden_size input neurons and output_size output neurons\n",
    "    torch.nn.Sigmoid()                         # Sigmoid activation function\n",
    ")\n",
    "\n",
    "#This creates a sequential container for the layers of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function (binary cross-entropy loss or BCE loss)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "'''\n",
    "Definition of binary cross-entropy loss:\n",
    "\n",
    "It measures the difference between the predicted probabilities \n",
    "of each class and the true probabilities, and outputs a single \n",
    "scalar value that represents the dissimilarity between the predicted \n",
    "and actual output (0 or 1 as the scalar value).\n",
    "\n",
    "In other words, binary cross-entropy loss is used to evaluate how well \n",
    "the model predicts a binary output (0 or 1) for a given input.\n",
    "\n",
    "'''\n",
    "\n",
    "# Define the optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.6994\n",
      "Epoch 2 loss: 0.6988\n",
      "Epoch 3 loss: 0.6983\n",
      "Epoch 4 loss: 0.6978\n",
      "Epoch 5 loss: 0.6974\n",
      "Epoch 6 loss: 0.6970\n",
      "Epoch 7 loss: 0.6966\n",
      "Epoch 8 loss: 0.6963\n",
      "Epoch 9 loss: 0.6960\n",
      "Epoch 10 loss: 0.6958\n",
      "Epoch 11 loss: 0.6956\n",
      "Epoch 12 loss: 0.6954\n",
      "Epoch 13 loss: 0.6952\n",
      "Epoch 14 loss: 0.6950\n",
      "Epoch 15 loss: 0.6949\n",
      "Epoch 16 loss: 0.6947\n",
      "Epoch 17 loss: 0.6946\n",
      "Epoch 18 loss: 0.6945\n",
      "Epoch 19 loss: 0.6944\n",
      "Epoch 20 loss: 0.6943\n",
      "Epoch 21 loss: 0.6942\n",
      "Epoch 22 loss: 0.6942\n",
      "Epoch 23 loss: 0.6941\n",
      "Epoch 24 loss: 0.6940\n",
      "Epoch 25 loss: 0.6940\n",
      "Epoch 26 loss: 0.6940\n",
      "Epoch 27 loss: 0.6939\n",
      "Epoch 28 loss: 0.6939\n",
      "Epoch 29 loss: 0.6938\n",
      "Epoch 30 loss: 0.6938\n",
      "Epoch 31 loss: 0.6938\n",
      "Epoch 32 loss: 0.6938\n",
      "Epoch 33 loss: 0.6937\n",
      "Epoch 34 loss: 0.6937\n",
      "Epoch 35 loss: 0.6937\n",
      "Epoch 36 loss: 0.6937\n",
      "Epoch 37 loss: 0.6937\n",
      "Epoch 38 loss: 0.6937\n",
      "Epoch 39 loss: 0.6936\n",
      "Epoch 40 loss: 0.6936\n",
      "Epoch 41 loss: 0.6936\n",
      "Epoch 42 loss: 0.6936\n",
      "Epoch 43 loss: 0.6936\n",
      "Epoch 44 loss: 0.6936\n",
      "Epoch 45 loss: 0.6936\n",
      "Epoch 46 loss: 0.6936\n",
      "Epoch 47 loss: 0.6936\n",
      "Epoch 48 loss: 0.6936\n",
      "Epoch 49 loss: 0.6936\n",
      "Epoch 50 loss: 0.6936\n",
      "Epoch 51 loss: 0.6936\n",
      "Epoch 52 loss: 0.6935\n",
      "Epoch 53 loss: 0.6935\n",
      "Epoch 54 loss: 0.6935\n",
      "Epoch 55 loss: 0.6935\n",
      "Epoch 56 loss: 0.6935\n",
      "Epoch 57 loss: 0.6935\n",
      "Epoch 58 loss: 0.6935\n",
      "Epoch 59 loss: 0.6935\n",
      "Epoch 60 loss: 0.6935\n",
      "Epoch 61 loss: 0.6935\n",
      "Epoch 62 loss: 0.6935\n",
      "Epoch 63 loss: 0.6935\n",
      "Epoch 64 loss: 0.6935\n",
      "Epoch 65 loss: 0.6935\n",
      "Epoch 66 loss: 0.6935\n",
      "Epoch 67 loss: 0.6935\n",
      "Epoch 68 loss: 0.6935\n",
      "Epoch 69 loss: 0.6935\n",
      "Epoch 70 loss: 0.6935\n",
      "Epoch 71 loss: 0.6935\n",
      "Epoch 72 loss: 0.6935\n",
      "Epoch 73 loss: 0.6935\n",
      "Epoch 74 loss: 0.6935\n",
      "Epoch 75 loss: 0.6935\n",
      "Epoch 76 loss: 0.6935\n",
      "Epoch 77 loss: 0.6935\n",
      "Epoch 78 loss: 0.6935\n",
      "Epoch 79 loss: 0.6935\n",
      "Epoch 80 loss: 0.6935\n",
      "Epoch 81 loss: 0.6935\n",
      "Epoch 82 loss: 0.6935\n",
      "Epoch 83 loss: 0.6935\n",
      "Epoch 84 loss: 0.6935\n",
      "Epoch 85 loss: 0.6935\n",
      "Epoch 86 loss: 0.6935\n",
      "Epoch 87 loss: 0.6935\n",
      "Epoch 88 loss: 0.6935\n",
      "Epoch 89 loss: 0.6935\n",
      "Epoch 90 loss: 0.6935\n",
      "Epoch 91 loss: 0.6935\n",
      "Epoch 92 loss: 0.6935\n",
      "Epoch 93 loss: 0.6935\n",
      "Epoch 94 loss: 0.6935\n",
      "Epoch 95 loss: 0.6935\n",
      "Epoch 96 loss: 0.6935\n",
      "Epoch 97 loss: 0.6935\n",
      "Epoch 98 loss: 0.6935\n",
      "Epoch 99 loss: 0.6935\n",
      "Epoch 100 loss: 0.6934\n",
      "Epoch 101 loss: 0.6934\n",
      "Epoch 102 loss: 0.6934\n",
      "Epoch 103 loss: 0.6934\n",
      "Epoch 104 loss: 0.6934\n",
      "Epoch 105 loss: 0.6934\n",
      "Epoch 106 loss: 0.6934\n",
      "Epoch 107 loss: 0.6934\n",
      "Epoch 108 loss: 0.6934\n",
      "Epoch 109 loss: 0.6934\n",
      "Epoch 110 loss: 0.6934\n",
      "Epoch 111 loss: 0.6934\n",
      "Epoch 112 loss: 0.6934\n",
      "Epoch 113 loss: 0.6934\n",
      "Epoch 114 loss: 0.6934\n",
      "Epoch 115 loss: 0.6934\n",
      "Epoch 116 loss: 0.6934\n",
      "Epoch 117 loss: 0.6934\n",
      "Epoch 118 loss: 0.6934\n",
      "Epoch 119 loss: 0.6934\n",
      "Epoch 120 loss: 0.6934\n",
      "Epoch 121 loss: 0.6934\n",
      "Epoch 122 loss: 0.6934\n",
      "Epoch 123 loss: 0.6934\n",
      "Epoch 124 loss: 0.6934\n",
      "Epoch 125 loss: 0.6934\n",
      "Epoch 126 loss: 0.6934\n",
      "Epoch 127 loss: 0.6934\n",
      "Epoch 128 loss: 0.6934\n",
      "Epoch 129 loss: 0.6934\n",
      "Epoch 130 loss: 0.6934\n",
      "Epoch 131 loss: 0.6934\n",
      "Epoch 132 loss: 0.6934\n",
      "Epoch 133 loss: 0.6934\n",
      "Epoch 134 loss: 0.6934\n",
      "Epoch 135 loss: 0.6934\n",
      "Epoch 136 loss: 0.6934\n",
      "Epoch 137 loss: 0.6934\n",
      "Epoch 138 loss: 0.6934\n",
      "Epoch 139 loss: 0.6934\n",
      "Epoch 140 loss: 0.6934\n",
      "Epoch 141 loss: 0.6934\n",
      "Epoch 142 loss: 0.6934\n",
      "Epoch 143 loss: 0.6934\n",
      "Epoch 144 loss: 0.6934\n",
      "Epoch 145 loss: 0.6934\n",
      "Epoch 146 loss: 0.6934\n",
      "Epoch 147 loss: 0.6934\n",
      "Epoch 148 loss: 0.6934\n",
      "Epoch 149 loss: 0.6934\n",
      "Epoch 150 loss: 0.6934\n",
      "Epoch 151 loss: 0.6934\n",
      "Epoch 152 loss: 0.6934\n",
      "Epoch 153 loss: 0.6934\n",
      "Epoch 154 loss: 0.6934\n",
      "Epoch 155 loss: 0.6934\n",
      "Epoch 156 loss: 0.6934\n",
      "Epoch 157 loss: 0.6934\n",
      "Epoch 158 loss: 0.6934\n",
      "Epoch 159 loss: 0.6934\n",
      "Epoch 160 loss: 0.6934\n",
      "Epoch 161 loss: 0.6934\n",
      "Epoch 162 loss: 0.6934\n",
      "Epoch 163 loss: 0.6933\n",
      "Epoch 164 loss: 0.6933\n",
      "Epoch 165 loss: 0.6933\n",
      "Epoch 166 loss: 0.6933\n",
      "Epoch 167 loss: 0.6933\n",
      "Epoch 168 loss: 0.6933\n",
      "Epoch 169 loss: 0.6933\n",
      "Epoch 170 loss: 0.6933\n",
      "Epoch 171 loss: 0.6933\n",
      "Epoch 172 loss: 0.6933\n",
      "Epoch 173 loss: 0.6933\n",
      "Epoch 174 loss: 0.6933\n",
      "Epoch 175 loss: 0.6933\n",
      "Epoch 176 loss: 0.6933\n",
      "Epoch 177 loss: 0.6933\n",
      "Epoch 178 loss: 0.6933\n",
      "Epoch 179 loss: 0.6933\n",
      "Epoch 180 loss: 0.6933\n",
      "Epoch 181 loss: 0.6933\n",
      "Epoch 182 loss: 0.6933\n",
      "Epoch 183 loss: 0.6933\n",
      "Epoch 184 loss: 0.6933\n",
      "Epoch 185 loss: 0.6933\n",
      "Epoch 186 loss: 0.6933\n",
      "Epoch 187 loss: 0.6933\n",
      "Epoch 188 loss: 0.6933\n",
      "Epoch 189 loss: 0.6933\n",
      "Epoch 190 loss: 0.6933\n",
      "Epoch 191 loss: 0.6933\n",
      "Epoch 192 loss: 0.6933\n",
      "Epoch 193 loss: 0.6933\n",
      "Epoch 194 loss: 0.6933\n",
      "Epoch 195 loss: 0.6933\n",
      "Epoch 196 loss: 0.6933\n",
      "Epoch 197 loss: 0.6933\n",
      "Epoch 198 loss: 0.6933\n",
      "Epoch 199 loss: 0.6933\n",
      "Epoch 200 loss: 0.6933\n",
      "Epoch 201 loss: 0.6933\n",
      "Epoch 202 loss: 0.6933\n",
      "Epoch 203 loss: 0.6933\n",
      "Epoch 204 loss: 0.6933\n",
      "Epoch 205 loss: 0.6933\n",
      "Epoch 206 loss: 0.6933\n",
      "Epoch 207 loss: 0.6933\n",
      "Epoch 208 loss: 0.6933\n",
      "Epoch 209 loss: 0.6933\n",
      "Epoch 210 loss: 0.6933\n",
      "Epoch 211 loss: 0.6933\n",
      "Epoch 212 loss: 0.6933\n",
      "Epoch 213 loss: 0.6933\n",
      "Epoch 214 loss: 0.6933\n",
      "Epoch 215 loss: 0.6933\n",
      "Epoch 216 loss: 0.6933\n",
      "Epoch 217 loss: 0.6933\n",
      "Epoch 218 loss: 0.6933\n",
      "Epoch 219 loss: 0.6933\n",
      "Epoch 220 loss: 0.6933\n",
      "Epoch 221 loss: 0.6933\n",
      "Epoch 222 loss: 0.6933\n",
      "Epoch 223 loss: 0.6933\n",
      "Epoch 224 loss: 0.6933\n",
      "Epoch 225 loss: 0.6933\n",
      "Epoch 226 loss: 0.6932\n",
      "Epoch 227 loss: 0.6932\n",
      "Epoch 228 loss: 0.6932\n",
      "Epoch 229 loss: 0.6932\n",
      "Epoch 230 loss: 0.6932\n",
      "Epoch 231 loss: 0.6932\n",
      "Epoch 232 loss: 0.6932\n",
      "Epoch 233 loss: 0.6932\n",
      "Epoch 234 loss: 0.6932\n",
      "Epoch 235 loss: 0.6932\n",
      "Epoch 236 loss: 0.6932\n",
      "Epoch 237 loss: 0.6932\n",
      "Epoch 238 loss: 0.6932\n",
      "Epoch 239 loss: 0.6932\n",
      "Epoch 240 loss: 0.6932\n",
      "Epoch 241 loss: 0.6932\n",
      "Epoch 242 loss: 0.6932\n",
      "Epoch 243 loss: 0.6932\n",
      "Epoch 244 loss: 0.6932\n",
      "Epoch 245 loss: 0.6932\n",
      "Epoch 246 loss: 0.6932\n",
      "Epoch 247 loss: 0.6932\n",
      "Epoch 248 loss: 0.6932\n",
      "Epoch 249 loss: 0.6932\n",
      "Epoch 250 loss: 0.6932\n",
      "Epoch 251 loss: 0.6932\n",
      "Epoch 252 loss: 0.6932\n",
      "Epoch 253 loss: 0.6932\n",
      "Epoch 254 loss: 0.6932\n",
      "Epoch 255 loss: 0.6932\n",
      "Epoch 256 loss: 0.6932\n",
      "Epoch 257 loss: 0.6932\n",
      "Epoch 258 loss: 0.6932\n",
      "Epoch 259 loss: 0.6932\n",
      "Epoch 260 loss: 0.6932\n",
      "Epoch 261 loss: 0.6932\n",
      "Epoch 262 loss: 0.6932\n",
      "Epoch 263 loss: 0.6932\n",
      "Epoch 264 loss: 0.6932\n",
      "Epoch 265 loss: 0.6932\n",
      "Epoch 266 loss: 0.6932\n",
      "Epoch 267 loss: 0.6932\n",
      "Epoch 268 loss: 0.6932\n",
      "Epoch 269 loss: 0.6932\n",
      "Epoch 270 loss: 0.6932\n",
      "Epoch 271 loss: 0.6932\n",
      "Epoch 272 loss: 0.6932\n",
      "Epoch 273 loss: 0.6932\n",
      "Epoch 274 loss: 0.6932\n",
      "Epoch 275 loss: 0.6932\n",
      "Epoch 276 loss: 0.6932\n",
      "Epoch 277 loss: 0.6932\n",
      "Epoch 278 loss: 0.6932\n",
      "Epoch 279 loss: 0.6932\n",
      "Epoch 280 loss: 0.6932\n",
      "Epoch 281 loss: 0.6932\n",
      "Epoch 282 loss: 0.6932\n",
      "Epoch 283 loss: 0.6932\n",
      "Epoch 284 loss: 0.6932\n",
      "Epoch 285 loss: 0.6932\n",
      "Epoch 286 loss: 0.6932\n",
      "Epoch 287 loss: 0.6931\n",
      "Epoch 288 loss: 0.6931\n",
      "Epoch 289 loss: 0.6931\n",
      "Epoch 290 loss: 0.6931\n",
      "Epoch 291 loss: 0.6931\n",
      "Epoch 292 loss: 0.6931\n",
      "Epoch 293 loss: 0.6931\n",
      "Epoch 294 loss: 0.6931\n",
      "Epoch 295 loss: 0.6931\n",
      "Epoch 296 loss: 0.6931\n",
      "Epoch 297 loss: 0.6931\n",
      "Epoch 298 loss: 0.6931\n",
      "Epoch 299 loss: 0.6931\n",
      "Epoch 300 loss: 0.6931\n",
      "Epoch 301 loss: 0.6931\n",
      "Epoch 302 loss: 0.6931\n",
      "Epoch 303 loss: 0.6931\n",
      "Epoch 304 loss: 0.6931\n",
      "Epoch 305 loss: 0.6931\n",
      "Epoch 306 loss: 0.6931\n",
      "Epoch 307 loss: 0.6931\n",
      "Epoch 308 loss: 0.6931\n",
      "Epoch 309 loss: 0.6931\n",
      "Epoch 310 loss: 0.6931\n",
      "Epoch 311 loss: 0.6931\n",
      "Epoch 312 loss: 0.6931\n",
      "Epoch 313 loss: 0.6931\n",
      "Epoch 314 loss: 0.6931\n",
      "Epoch 315 loss: 0.6931\n",
      "Epoch 316 loss: 0.6931\n",
      "Epoch 317 loss: 0.6931\n",
      "Epoch 318 loss: 0.6931\n",
      "Epoch 319 loss: 0.6931\n",
      "Epoch 320 loss: 0.6931\n",
      "Epoch 321 loss: 0.6931\n",
      "Epoch 322 loss: 0.6931\n",
      "Epoch 323 loss: 0.6931\n",
      "Epoch 324 loss: 0.6931\n",
      "Epoch 325 loss: 0.6931\n",
      "Epoch 326 loss: 0.6931\n",
      "Epoch 327 loss: 0.6931\n",
      "Epoch 328 loss: 0.6931\n",
      "Epoch 329 loss: 0.6931\n",
      "Epoch 330 loss: 0.6931\n",
      "Epoch 331 loss: 0.6931\n",
      "Epoch 332 loss: 0.6931\n",
      "Epoch 333 loss: 0.6931\n",
      "Epoch 334 loss: 0.6931\n",
      "Epoch 335 loss: 0.6931\n",
      "Epoch 336 loss: 0.6931\n",
      "Epoch 337 loss: 0.6931\n",
      "Epoch 338 loss: 0.6931\n",
      "Epoch 339 loss: 0.6931\n",
      "Epoch 340 loss: 0.6931\n",
      "Epoch 341 loss: 0.6931\n",
      "Epoch 342 loss: 0.6931\n",
      "Epoch 343 loss: 0.6931\n",
      "Epoch 344 loss: 0.6931\n",
      "Epoch 345 loss: 0.6930\n",
      "Epoch 346 loss: 0.6930\n",
      "Epoch 347 loss: 0.6930\n",
      "Epoch 348 loss: 0.6930\n",
      "Epoch 349 loss: 0.6930\n",
      "Epoch 350 loss: 0.6930\n",
      "Epoch 351 loss: 0.6930\n",
      "Epoch 352 loss: 0.6930\n",
      "Epoch 353 loss: 0.6930\n",
      "Epoch 354 loss: 0.6930\n",
      "Epoch 355 loss: 0.6930\n",
      "Epoch 356 loss: 0.6930\n",
      "Epoch 357 loss: 0.6930\n",
      "Epoch 358 loss: 0.6930\n",
      "Epoch 359 loss: 0.6930\n",
      "Epoch 360 loss: 0.6930\n",
      "Epoch 361 loss: 0.6930\n",
      "Epoch 362 loss: 0.6930\n",
      "Epoch 363 loss: 0.6930\n",
      "Epoch 364 loss: 0.6930\n",
      "Epoch 365 loss: 0.6930\n",
      "Epoch 366 loss: 0.6930\n",
      "Epoch 367 loss: 0.6930\n",
      "Epoch 368 loss: 0.6930\n",
      "Epoch 369 loss: 0.6930\n",
      "Epoch 370 loss: 0.6930\n",
      "Epoch 371 loss: 0.6930\n",
      "Epoch 372 loss: 0.6930\n",
      "Epoch 373 loss: 0.6930\n",
      "Epoch 374 loss: 0.6930\n",
      "Epoch 375 loss: 0.6930\n",
      "Epoch 376 loss: 0.6930\n",
      "Epoch 377 loss: 0.6930\n",
      "Epoch 378 loss: 0.6930\n",
      "Epoch 379 loss: 0.6930\n",
      "Epoch 380 loss: 0.6930\n",
      "Epoch 381 loss: 0.6930\n",
      "Epoch 382 loss: 0.6930\n",
      "Epoch 383 loss: 0.6930\n",
      "Epoch 384 loss: 0.6930\n",
      "Epoch 385 loss: 0.6930\n",
      "Epoch 386 loss: 0.6930\n",
      "Epoch 387 loss: 0.6930\n",
      "Epoch 388 loss: 0.6930\n",
      "Epoch 389 loss: 0.6930\n",
      "Epoch 390 loss: 0.6930\n",
      "Epoch 391 loss: 0.6930\n",
      "Epoch 392 loss: 0.6930\n",
      "Epoch 393 loss: 0.6930\n",
      "Epoch 394 loss: 0.6930\n",
      "Epoch 395 loss: 0.6930\n",
      "Epoch 396 loss: 0.6930\n",
      "Epoch 397 loss: 0.6930\n",
      "Epoch 398 loss: 0.6930\n",
      "Epoch 399 loss: 0.6930\n",
      "Epoch 400 loss: 0.6930\n",
      "Epoch 401 loss: 0.6929\n",
      "Epoch 402 loss: 0.6929\n",
      "Epoch 403 loss: 0.6929\n",
      "Epoch 404 loss: 0.6929\n",
      "Epoch 405 loss: 0.6929\n",
      "Epoch 406 loss: 0.6929\n",
      "Epoch 407 loss: 0.6929\n",
      "Epoch 408 loss: 0.6929\n",
      "Epoch 409 loss: 0.6929\n",
      "Epoch 410 loss: 0.6929\n",
      "Epoch 411 loss: 0.6929\n",
      "Epoch 412 loss: 0.6929\n",
      "Epoch 413 loss: 0.6929\n",
      "Epoch 414 loss: 0.6929\n",
      "Epoch 415 loss: 0.6929\n",
      "Epoch 416 loss: 0.6929\n",
      "Epoch 417 loss: 0.6929\n",
      "Epoch 418 loss: 0.6929\n",
      "Epoch 419 loss: 0.6929\n",
      "Epoch 420 loss: 0.6929\n",
      "Epoch 421 loss: 0.6929\n",
      "Epoch 422 loss: 0.6929\n",
      "Epoch 423 loss: 0.6929\n",
      "Epoch 424 loss: 0.6929\n",
      "Epoch 425 loss: 0.6929\n",
      "Epoch 426 loss: 0.6929\n",
      "Epoch 427 loss: 0.6929\n",
      "Epoch 428 loss: 0.6929\n",
      "Epoch 429 loss: 0.6929\n",
      "Epoch 430 loss: 0.6929\n",
      "Epoch 431 loss: 0.6929\n",
      "Epoch 432 loss: 0.6929\n",
      "Epoch 433 loss: 0.6929\n",
      "Epoch 434 loss: 0.6929\n",
      "Epoch 435 loss: 0.6929\n",
      "Epoch 436 loss: 0.6929\n",
      "Epoch 437 loss: 0.6929\n",
      "Epoch 438 loss: 0.6929\n",
      "Epoch 439 loss: 0.6929\n",
      "Epoch 440 loss: 0.6929\n",
      "Epoch 441 loss: 0.6929\n",
      "Epoch 442 loss: 0.6929\n",
      "Epoch 443 loss: 0.6929\n",
      "Epoch 444 loss: 0.6929\n",
      "Epoch 445 loss: 0.6929\n",
      "Epoch 446 loss: 0.6929\n",
      "Epoch 447 loss: 0.6929\n",
      "Epoch 448 loss: 0.6929\n",
      "Epoch 449 loss: 0.6929\n",
      "Epoch 450 loss: 0.6929\n",
      "Epoch 451 loss: 0.6929\n",
      "Epoch 452 loss: 0.6929\n",
      "Epoch 453 loss: 0.6929\n",
      "Epoch 454 loss: 0.6929\n",
      "Epoch 455 loss: 0.6928\n",
      "Epoch 456 loss: 0.6928\n",
      "Epoch 457 loss: 0.6928\n",
      "Epoch 458 loss: 0.6928\n",
      "Epoch 459 loss: 0.6928\n",
      "Epoch 460 loss: 0.6928\n",
      "Epoch 461 loss: 0.6928\n",
      "Epoch 462 loss: 0.6928\n",
      "Epoch 463 loss: 0.6928\n",
      "Epoch 464 loss: 0.6928\n",
      "Epoch 465 loss: 0.6928\n",
      "Epoch 466 loss: 0.6928\n",
      "Epoch 467 loss: 0.6928\n",
      "Epoch 468 loss: 0.6928\n",
      "Epoch 469 loss: 0.6928\n",
      "Epoch 470 loss: 0.6928\n",
      "Epoch 471 loss: 0.6928\n",
      "Epoch 472 loss: 0.6928\n",
      "Epoch 473 loss: 0.6928\n",
      "Epoch 474 loss: 0.6928\n",
      "Epoch 475 loss: 0.6928\n",
      "Epoch 476 loss: 0.6928\n",
      "Epoch 477 loss: 0.6928\n",
      "Epoch 478 loss: 0.6928\n",
      "Epoch 479 loss: 0.6928\n",
      "Epoch 480 loss: 0.6928\n",
      "Epoch 481 loss: 0.6928\n",
      "Epoch 482 loss: 0.6928\n",
      "Epoch 483 loss: 0.6928\n",
      "Epoch 484 loss: 0.6928\n",
      "Epoch 485 loss: 0.6928\n",
      "Epoch 486 loss: 0.6928\n",
      "Epoch 487 loss: 0.6928\n",
      "Epoch 488 loss: 0.6928\n",
      "Epoch 489 loss: 0.6928\n",
      "Epoch 490 loss: 0.6928\n",
      "Epoch 491 loss: 0.6928\n",
      "Epoch 492 loss: 0.6928\n",
      "Epoch 493 loss: 0.6928\n",
      "Epoch 494 loss: 0.6928\n",
      "Epoch 495 loss: 0.6928\n",
      "Epoch 496 loss: 0.6928\n",
      "Epoch 497 loss: 0.6928\n",
      "Epoch 498 loss: 0.6928\n",
      "Epoch 499 loss: 0.6928\n",
      "Epoch 500 loss: 0.6928\n",
      "Epoch 501 loss: 0.6928\n",
      "Epoch 502 loss: 0.6928\n",
      "Epoch 503 loss: 0.6928\n",
      "Epoch 504 loss: 0.6928\n",
      "Epoch 505 loss: 0.6928\n",
      "Epoch 506 loss: 0.6927\n",
      "Epoch 507 loss: 0.6927\n",
      "Epoch 508 loss: 0.6927\n",
      "Epoch 509 loss: 0.6927\n",
      "Epoch 510 loss: 0.6927\n",
      "Epoch 511 loss: 0.6927\n",
      "Epoch 512 loss: 0.6927\n",
      "Epoch 513 loss: 0.6927\n",
      "Epoch 514 loss: 0.6927\n",
      "Epoch 515 loss: 0.6927\n",
      "Epoch 516 loss: 0.6927\n",
      "Epoch 517 loss: 0.6927\n",
      "Epoch 518 loss: 0.6927\n",
      "Epoch 519 loss: 0.6927\n",
      "Epoch 520 loss: 0.6927\n",
      "Epoch 521 loss: 0.6927\n",
      "Epoch 522 loss: 0.6927\n",
      "Epoch 523 loss: 0.6927\n",
      "Epoch 524 loss: 0.6927\n",
      "Epoch 525 loss: 0.6927\n",
      "Epoch 526 loss: 0.6927\n",
      "Epoch 527 loss: 0.6927\n",
      "Epoch 528 loss: 0.6927\n",
      "Epoch 529 loss: 0.6927\n",
      "Epoch 530 loss: 0.6927\n",
      "Epoch 531 loss: 0.6927\n",
      "Epoch 532 loss: 0.6927\n",
      "Epoch 533 loss: 0.6927\n",
      "Epoch 534 loss: 0.6927\n",
      "Epoch 535 loss: 0.6927\n",
      "Epoch 536 loss: 0.6927\n",
      "Epoch 537 loss: 0.6927\n",
      "Epoch 538 loss: 0.6927\n",
      "Epoch 539 loss: 0.6927\n",
      "Epoch 540 loss: 0.6927\n",
      "Epoch 541 loss: 0.6927\n",
      "Epoch 542 loss: 0.6927\n",
      "Epoch 543 loss: 0.6927\n",
      "Epoch 544 loss: 0.6927\n",
      "Epoch 545 loss: 0.6927\n",
      "Epoch 546 loss: 0.6927\n",
      "Epoch 547 loss: 0.6927\n",
      "Epoch 548 loss: 0.6927\n",
      "Epoch 549 loss: 0.6927\n",
      "Epoch 550 loss: 0.6927\n",
      "Epoch 551 loss: 0.6927\n",
      "Epoch 552 loss: 0.6927\n",
      "Epoch 553 loss: 0.6927\n",
      "Epoch 554 loss: 0.6927\n",
      "Epoch 555 loss: 0.6926\n",
      "Epoch 556 loss: 0.6926\n",
      "Epoch 557 loss: 0.6926\n",
      "Epoch 558 loss: 0.6926\n",
      "Epoch 559 loss: 0.6926\n",
      "Epoch 560 loss: 0.6926\n",
      "Epoch 561 loss: 0.6926\n",
      "Epoch 562 loss: 0.6926\n",
      "Epoch 563 loss: 0.6926\n",
      "Epoch 564 loss: 0.6926\n",
      "Epoch 565 loss: 0.6926\n",
      "Epoch 566 loss: 0.6926\n",
      "Epoch 567 loss: 0.6926\n",
      "Epoch 568 loss: 0.6926\n",
      "Epoch 569 loss: 0.6926\n",
      "Epoch 570 loss: 0.6926\n",
      "Epoch 571 loss: 0.6926\n",
      "Epoch 572 loss: 0.6926\n",
      "Epoch 573 loss: 0.6926\n",
      "Epoch 574 loss: 0.6926\n",
      "Epoch 575 loss: 0.6926\n",
      "Epoch 576 loss: 0.6926\n",
      "Epoch 577 loss: 0.6926\n",
      "Epoch 578 loss: 0.6926\n",
      "Epoch 579 loss: 0.6926\n",
      "Epoch 580 loss: 0.6926\n",
      "Epoch 581 loss: 0.6926\n",
      "Epoch 582 loss: 0.6926\n",
      "Epoch 583 loss: 0.6926\n",
      "Epoch 584 loss: 0.6926\n",
      "Epoch 585 loss: 0.6926\n",
      "Epoch 586 loss: 0.6926\n",
      "Epoch 587 loss: 0.6926\n",
      "Epoch 588 loss: 0.6926\n",
      "Epoch 589 loss: 0.6926\n",
      "Epoch 590 loss: 0.6926\n",
      "Epoch 591 loss: 0.6926\n",
      "Epoch 592 loss: 0.6926\n",
      "Epoch 593 loss: 0.6926\n",
      "Epoch 594 loss: 0.6926\n",
      "Epoch 595 loss: 0.6926\n",
      "Epoch 596 loss: 0.6926\n",
      "Epoch 597 loss: 0.6926\n",
      "Epoch 598 loss: 0.6926\n",
      "Epoch 599 loss: 0.6926\n",
      "Epoch 600 loss: 0.6926\n",
      "Epoch 601 loss: 0.6925\n",
      "Epoch 602 loss: 0.6925\n",
      "Epoch 603 loss: 0.6925\n",
      "Epoch 604 loss: 0.6925\n",
      "Epoch 605 loss: 0.6925\n",
      "Epoch 606 loss: 0.6925\n",
      "Epoch 607 loss: 0.6925\n",
      "Epoch 608 loss: 0.6925\n",
      "Epoch 609 loss: 0.6925\n",
      "Epoch 610 loss: 0.6925\n",
      "Epoch 611 loss: 0.6925\n",
      "Epoch 612 loss: 0.6925\n",
      "Epoch 613 loss: 0.6925\n",
      "Epoch 614 loss: 0.6925\n",
      "Epoch 615 loss: 0.6925\n",
      "Epoch 616 loss: 0.6925\n",
      "Epoch 617 loss: 0.6925\n",
      "Epoch 618 loss: 0.6925\n",
      "Epoch 619 loss: 0.6925\n",
      "Epoch 620 loss: 0.6925\n",
      "Epoch 621 loss: 0.6925\n",
      "Epoch 622 loss: 0.6925\n",
      "Epoch 623 loss: 0.6925\n",
      "Epoch 624 loss: 0.6925\n",
      "Epoch 625 loss: 0.6925\n",
      "Epoch 626 loss: 0.6925\n",
      "Epoch 627 loss: 0.6925\n",
      "Epoch 628 loss: 0.6925\n",
      "Epoch 629 loss: 0.6925\n",
      "Epoch 630 loss: 0.6925\n",
      "Epoch 631 loss: 0.6925\n",
      "Epoch 632 loss: 0.6925\n",
      "Epoch 633 loss: 0.6925\n",
      "Epoch 634 loss: 0.6925\n",
      "Epoch 635 loss: 0.6925\n",
      "Epoch 636 loss: 0.6925\n",
      "Epoch 637 loss: 0.6925\n",
      "Epoch 638 loss: 0.6925\n",
      "Epoch 639 loss: 0.6925\n",
      "Epoch 640 loss: 0.6925\n",
      "Epoch 641 loss: 0.6925\n",
      "Epoch 642 loss: 0.6925\n",
      "Epoch 643 loss: 0.6925\n",
      "Epoch 644 loss: 0.6925\n",
      "Epoch 645 loss: 0.6924\n",
      "Epoch 646 loss: 0.6924\n",
      "Epoch 647 loss: 0.6924\n",
      "Epoch 648 loss: 0.6924\n",
      "Epoch 649 loss: 0.6924\n",
      "Epoch 650 loss: 0.6924\n",
      "Epoch 651 loss: 0.6924\n",
      "Epoch 652 loss: 0.6924\n",
      "Epoch 653 loss: 0.6924\n",
      "Epoch 654 loss: 0.6924\n",
      "Epoch 655 loss: 0.6924\n",
      "Epoch 656 loss: 0.6924\n",
      "Epoch 657 loss: 0.6924\n",
      "Epoch 658 loss: 0.6924\n",
      "Epoch 659 loss: 0.6924\n",
      "Epoch 660 loss: 0.6924\n",
      "Epoch 661 loss: 0.6924\n",
      "Epoch 662 loss: 0.6924\n",
      "Epoch 663 loss: 0.6924\n",
      "Epoch 664 loss: 0.6924\n",
      "Epoch 665 loss: 0.6924\n",
      "Epoch 666 loss: 0.6924\n",
      "Epoch 667 loss: 0.6924\n",
      "Epoch 668 loss: 0.6924\n",
      "Epoch 669 loss: 0.6924\n",
      "Epoch 670 loss: 0.6924\n",
      "Epoch 671 loss: 0.6924\n",
      "Epoch 672 loss: 0.6924\n",
      "Epoch 673 loss: 0.6924\n",
      "Epoch 674 loss: 0.6924\n",
      "Epoch 675 loss: 0.6924\n",
      "Epoch 676 loss: 0.6924\n",
      "Epoch 677 loss: 0.6924\n",
      "Epoch 678 loss: 0.6924\n",
      "Epoch 679 loss: 0.6924\n",
      "Epoch 680 loss: 0.6924\n",
      "Epoch 681 loss: 0.6924\n",
      "Epoch 682 loss: 0.6924\n",
      "Epoch 683 loss: 0.6924\n",
      "Epoch 684 loss: 0.6924\n",
      "Epoch 685 loss: 0.6924\n",
      "Epoch 686 loss: 0.6923\n",
      "Epoch 687 loss: 0.6923\n",
      "Epoch 688 loss: 0.6923\n",
      "Epoch 689 loss: 0.6923\n",
      "Epoch 690 loss: 0.6923\n",
      "Epoch 691 loss: 0.6923\n",
      "Epoch 692 loss: 0.6923\n",
      "Epoch 693 loss: 0.6923\n",
      "Epoch 694 loss: 0.6923\n",
      "Epoch 695 loss: 0.6923\n",
      "Epoch 696 loss: 0.6923\n",
      "Epoch 697 loss: 0.6923\n",
      "Epoch 698 loss: 0.6923\n",
      "Epoch 699 loss: 0.6923\n",
      "Epoch 700 loss: 0.6923\n",
      "Epoch 701 loss: 0.6923\n",
      "Epoch 702 loss: 0.6923\n",
      "Epoch 703 loss: 0.6923\n",
      "Epoch 704 loss: 0.6923\n",
      "Epoch 705 loss: 0.6923\n",
      "Epoch 706 loss: 0.6923\n",
      "Epoch 707 loss: 0.6923\n",
      "Epoch 708 loss: 0.6923\n",
      "Epoch 709 loss: 0.6923\n",
      "Epoch 710 loss: 0.6923\n",
      "Epoch 711 loss: 0.6923\n",
      "Epoch 712 loss: 0.6923\n",
      "Epoch 713 loss: 0.6923\n",
      "Epoch 714 loss: 0.6923\n",
      "Epoch 715 loss: 0.6923\n",
      "Epoch 716 loss: 0.6923\n",
      "Epoch 717 loss: 0.6923\n",
      "Epoch 718 loss: 0.6923\n",
      "Epoch 719 loss: 0.6923\n",
      "Epoch 720 loss: 0.6923\n",
      "Epoch 721 loss: 0.6923\n",
      "Epoch 722 loss: 0.6923\n",
      "Epoch 723 loss: 0.6923\n",
      "Epoch 724 loss: 0.6923\n",
      "Epoch 725 loss: 0.6923\n",
      "Epoch 726 loss: 0.6922\n",
      "Epoch 727 loss: 0.6922\n",
      "Epoch 728 loss: 0.6922\n",
      "Epoch 729 loss: 0.6922\n",
      "Epoch 730 loss: 0.6922\n",
      "Epoch 731 loss: 0.6922\n",
      "Epoch 732 loss: 0.6922\n",
      "Epoch 733 loss: 0.6922\n",
      "Epoch 734 loss: 0.6922\n",
      "Epoch 735 loss: 0.6922\n",
      "Epoch 736 loss: 0.6922\n",
      "Epoch 737 loss: 0.6922\n",
      "Epoch 738 loss: 0.6922\n",
      "Epoch 739 loss: 0.6922\n",
      "Epoch 740 loss: 0.6922\n",
      "Epoch 741 loss: 0.6922\n",
      "Epoch 742 loss: 0.6922\n",
      "Epoch 743 loss: 0.6922\n",
      "Epoch 744 loss: 0.6922\n",
      "Epoch 745 loss: 0.6922\n",
      "Epoch 746 loss: 0.6922\n",
      "Epoch 747 loss: 0.6922\n",
      "Epoch 748 loss: 0.6922\n",
      "Epoch 749 loss: 0.6922\n",
      "Epoch 750 loss: 0.6922\n",
      "Epoch 751 loss: 0.6922\n",
      "Epoch 752 loss: 0.6922\n",
      "Epoch 753 loss: 0.6922\n",
      "Epoch 754 loss: 0.6922\n",
      "Epoch 755 loss: 0.6922\n",
      "Epoch 756 loss: 0.6922\n",
      "Epoch 757 loss: 0.6922\n",
      "Epoch 758 loss: 0.6922\n",
      "Epoch 759 loss: 0.6922\n",
      "Epoch 760 loss: 0.6922\n",
      "Epoch 761 loss: 0.6922\n",
      "Epoch 762 loss: 0.6922\n",
      "Epoch 763 loss: 0.6921\n",
      "Epoch 764 loss: 0.6921\n",
      "Epoch 765 loss: 0.6921\n",
      "Epoch 766 loss: 0.6921\n",
      "Epoch 767 loss: 0.6921\n",
      "Epoch 768 loss: 0.6921\n",
      "Epoch 769 loss: 0.6921\n",
      "Epoch 770 loss: 0.6921\n",
      "Epoch 771 loss: 0.6921\n",
      "Epoch 772 loss: 0.6921\n",
      "Epoch 773 loss: 0.6921\n",
      "Epoch 774 loss: 0.6921\n",
      "Epoch 775 loss: 0.6921\n",
      "Epoch 776 loss: 0.6921\n",
      "Epoch 777 loss: 0.6921\n",
      "Epoch 778 loss: 0.6921\n",
      "Epoch 779 loss: 0.6921\n",
      "Epoch 780 loss: 0.6921\n",
      "Epoch 781 loss: 0.6921\n",
      "Epoch 782 loss: 0.6921\n",
      "Epoch 783 loss: 0.6921\n",
      "Epoch 784 loss: 0.6921\n",
      "Epoch 785 loss: 0.6921\n",
      "Epoch 786 loss: 0.6921\n",
      "Epoch 787 loss: 0.6921\n",
      "Epoch 788 loss: 0.6921\n",
      "Epoch 789 loss: 0.6921\n",
      "Epoch 790 loss: 0.6921\n",
      "Epoch 791 loss: 0.6921\n",
      "Epoch 792 loss: 0.6921\n",
      "Epoch 793 loss: 0.6921\n",
      "Epoch 794 loss: 0.6921\n",
      "Epoch 795 loss: 0.6921\n",
      "Epoch 796 loss: 0.6921\n",
      "Epoch 797 loss: 0.6921\n",
      "Epoch 798 loss: 0.6921\n",
      "Epoch 799 loss: 0.6920\n",
      "Epoch 800 loss: 0.6920\n",
      "Epoch 801 loss: 0.6920\n",
      "Epoch 802 loss: 0.6920\n",
      "Epoch 803 loss: 0.6920\n",
      "Epoch 804 loss: 0.6920\n",
      "Epoch 805 loss: 0.6920\n",
      "Epoch 806 loss: 0.6920\n",
      "Epoch 807 loss: 0.6920\n",
      "Epoch 808 loss: 0.6920\n",
      "Epoch 809 loss: 0.6920\n",
      "Epoch 810 loss: 0.6920\n",
      "Epoch 811 loss: 0.6920\n",
      "Epoch 812 loss: 0.6920\n",
      "Epoch 813 loss: 0.6920\n",
      "Epoch 814 loss: 0.6920\n",
      "Epoch 815 loss: 0.6920\n",
      "Epoch 816 loss: 0.6920\n",
      "Epoch 817 loss: 0.6920\n",
      "Epoch 818 loss: 0.6920\n",
      "Epoch 819 loss: 0.6920\n",
      "Epoch 820 loss: 0.6920\n",
      "Epoch 821 loss: 0.6920\n",
      "Epoch 822 loss: 0.6920\n",
      "Epoch 823 loss: 0.6920\n",
      "Epoch 824 loss: 0.6920\n",
      "Epoch 825 loss: 0.6920\n",
      "Epoch 826 loss: 0.6920\n",
      "Epoch 827 loss: 0.6920\n",
      "Epoch 828 loss: 0.6920\n",
      "Epoch 829 loss: 0.6920\n",
      "Epoch 830 loss: 0.6920\n",
      "Epoch 831 loss: 0.6920\n",
      "Epoch 832 loss: 0.6920\n",
      "Epoch 833 loss: 0.6919\n",
      "Epoch 834 loss: 0.6919\n",
      "Epoch 835 loss: 0.6919\n",
      "Epoch 836 loss: 0.6919\n",
      "Epoch 837 loss: 0.6919\n",
      "Epoch 838 loss: 0.6919\n",
      "Epoch 839 loss: 0.6919\n",
      "Epoch 840 loss: 0.6919\n",
      "Epoch 841 loss: 0.6919\n",
      "Epoch 842 loss: 0.6919\n",
      "Epoch 843 loss: 0.6919\n",
      "Epoch 844 loss: 0.6919\n",
      "Epoch 845 loss: 0.6919\n",
      "Epoch 846 loss: 0.6919\n",
      "Epoch 847 loss: 0.6919\n",
      "Epoch 848 loss: 0.6919\n",
      "Epoch 849 loss: 0.6919\n",
      "Epoch 850 loss: 0.6919\n",
      "Epoch 851 loss: 0.6919\n",
      "Epoch 852 loss: 0.6919\n",
      "Epoch 853 loss: 0.6919\n",
      "Epoch 854 loss: 0.6919\n",
      "Epoch 855 loss: 0.6919\n",
      "Epoch 856 loss: 0.6919\n",
      "Epoch 857 loss: 0.6919\n",
      "Epoch 858 loss: 0.6919\n",
      "Epoch 859 loss: 0.6919\n",
      "Epoch 860 loss: 0.6919\n",
      "Epoch 861 loss: 0.6919\n",
      "Epoch 862 loss: 0.6919\n",
      "Epoch 863 loss: 0.6919\n",
      "Epoch 864 loss: 0.6919\n",
      "Epoch 865 loss: 0.6918\n",
      "Epoch 866 loss: 0.6918\n",
      "Epoch 867 loss: 0.6918\n",
      "Epoch 868 loss: 0.6918\n",
      "Epoch 869 loss: 0.6918\n",
      "Epoch 870 loss: 0.6918\n",
      "Epoch 871 loss: 0.6918\n",
      "Epoch 872 loss: 0.6918\n",
      "Epoch 873 loss: 0.6918\n",
      "Epoch 874 loss: 0.6918\n",
      "Epoch 875 loss: 0.6918\n",
      "Epoch 876 loss: 0.6918\n",
      "Epoch 877 loss: 0.6918\n",
      "Epoch 878 loss: 0.6918\n",
      "Epoch 879 loss: 0.6918\n",
      "Epoch 880 loss: 0.6918\n",
      "Epoch 881 loss: 0.6918\n",
      "Epoch 882 loss: 0.6918\n",
      "Epoch 883 loss: 0.6918\n",
      "Epoch 884 loss: 0.6918\n",
      "Epoch 885 loss: 0.6918\n",
      "Epoch 886 loss: 0.6918\n",
      "Epoch 887 loss: 0.6918\n",
      "Epoch 888 loss: 0.6918\n",
      "Epoch 889 loss: 0.6918\n",
      "Epoch 890 loss: 0.6918\n",
      "Epoch 891 loss: 0.6918\n",
      "Epoch 892 loss: 0.6918\n",
      "Epoch 893 loss: 0.6918\n",
      "Epoch 894 loss: 0.6918\n",
      "Epoch 895 loss: 0.6918\n",
      "Epoch 896 loss: 0.6917\n",
      "Epoch 897 loss: 0.6917\n",
      "Epoch 898 loss: 0.6917\n",
      "Epoch 899 loss: 0.6917\n",
      "Epoch 900 loss: 0.6917\n",
      "Epoch 901 loss: 0.6917\n",
      "Epoch 902 loss: 0.6917\n",
      "Epoch 903 loss: 0.6917\n",
      "Epoch 904 loss: 0.6917\n",
      "Epoch 905 loss: 0.6917\n",
      "Epoch 906 loss: 0.6917\n",
      "Epoch 907 loss: 0.6917\n",
      "Epoch 908 loss: 0.6917\n",
      "Epoch 909 loss: 0.6917\n",
      "Epoch 910 loss: 0.6917\n",
      "Epoch 911 loss: 0.6917\n",
      "Epoch 912 loss: 0.6917\n",
      "Epoch 913 loss: 0.6917\n",
      "Epoch 914 loss: 0.6917\n",
      "Epoch 915 loss: 0.6917\n",
      "Epoch 916 loss: 0.6917\n",
      "Epoch 917 loss: 0.6917\n",
      "Epoch 918 loss: 0.6917\n",
      "Epoch 919 loss: 0.6917\n",
      "Epoch 920 loss: 0.6917\n",
      "Epoch 921 loss: 0.6917\n",
      "Epoch 922 loss: 0.6917\n",
      "Epoch 923 loss: 0.6917\n",
      "Epoch 924 loss: 0.6917\n",
      "Epoch 925 loss: 0.6916\n",
      "Epoch 926 loss: 0.6916\n",
      "Epoch 927 loss: 0.6916\n",
      "Epoch 928 loss: 0.6916\n",
      "Epoch 929 loss: 0.6916\n",
      "Epoch 930 loss: 0.6916\n",
      "Epoch 931 loss: 0.6916\n",
      "Epoch 932 loss: 0.6916\n",
      "Epoch 933 loss: 0.6916\n",
      "Epoch 934 loss: 0.6916\n",
      "Epoch 935 loss: 0.6916\n",
      "Epoch 936 loss: 0.6916\n",
      "Epoch 937 loss: 0.6916\n",
      "Epoch 938 loss: 0.6916\n",
      "Epoch 939 loss: 0.6916\n",
      "Epoch 940 loss: 0.6916\n",
      "Epoch 941 loss: 0.6916\n",
      "Epoch 942 loss: 0.6916\n",
      "Epoch 943 loss: 0.6916\n",
      "Epoch 944 loss: 0.6916\n",
      "Epoch 945 loss: 0.6916\n",
      "Epoch 946 loss: 0.6916\n",
      "Epoch 947 loss: 0.6916\n",
      "Epoch 948 loss: 0.6916\n",
      "Epoch 949 loss: 0.6916\n",
      "Epoch 950 loss: 0.6916\n",
      "Epoch 951 loss: 0.6916\n",
      "Epoch 952 loss: 0.6916\n",
      "Epoch 953 loss: 0.6915\n",
      "Epoch 954 loss: 0.6915\n",
      "Epoch 955 loss: 0.6915\n",
      "Epoch 956 loss: 0.6915\n",
      "Epoch 957 loss: 0.6915\n",
      "Epoch 958 loss: 0.6915\n",
      "Epoch 959 loss: 0.6915\n",
      "Epoch 960 loss: 0.6915\n",
      "Epoch 961 loss: 0.6915\n",
      "Epoch 962 loss: 0.6915\n",
      "Epoch 963 loss: 0.6915\n",
      "Epoch 964 loss: 0.6915\n",
      "Epoch 965 loss: 0.6915\n",
      "Epoch 966 loss: 0.6915\n",
      "Epoch 967 loss: 0.6915\n",
      "Epoch 968 loss: 0.6915\n",
      "Epoch 969 loss: 0.6915\n",
      "Epoch 970 loss: 0.6915\n",
      "Epoch 971 loss: 0.6915\n",
      "Epoch 972 loss: 0.6915\n",
      "Epoch 973 loss: 0.6915\n",
      "Epoch 974 loss: 0.6915\n",
      "Epoch 975 loss: 0.6915\n",
      "Epoch 976 loss: 0.6915\n",
      "Epoch 977 loss: 0.6915\n",
      "Epoch 978 loss: 0.6915\n",
      "Epoch 979 loss: 0.6915\n",
      "Epoch 980 loss: 0.6914\n",
      "Epoch 981 loss: 0.6914\n",
      "Epoch 982 loss: 0.6914\n",
      "Epoch 983 loss: 0.6914\n",
      "Epoch 984 loss: 0.6914\n",
      "Epoch 985 loss: 0.6914\n",
      "Epoch 986 loss: 0.6914\n",
      "Epoch 987 loss: 0.6914\n",
      "Epoch 988 loss: 0.6914\n",
      "Epoch 989 loss: 0.6914\n",
      "Epoch 990 loss: 0.6914\n",
      "Epoch 991 loss: 0.6914\n",
      "Epoch 992 loss: 0.6914\n",
      "Epoch 993 loss: 0.6914\n",
      "Epoch 994 loss: 0.6914\n",
      "Epoch 995 loss: 0.6914\n",
      "Epoch 996 loss: 0.6914\n",
      "Epoch 997 loss: 0.6914\n",
      "Epoch 998 loss: 0.6914\n",
      "Epoch 999 loss: 0.6914\n",
      "Epoch 1000 loss: 0.6914\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 1000 epochs\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Forward pass: compute predicted y by passing X to the model\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(f'Epoch {epoch + 1} loss: {loss.item():.4f}')\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output: tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    # Define new input data\n",
    "    X_test = torch.Tensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "    # Compute the output of the model on the new input data\n",
    "    y_pred = model(X_test)\n",
    "\n",
    "    # Print the predicted output\n",
    "    print(f'Predicted output: {y_pred.round()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8b93b4dae0ba1fdb56329cae2fb23b7f41a62a212f9a2d02c2934927b7e2cbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
